{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain Expression Language (LCEL) is a declarative language designed to simplify the composition of complex text-based chains using Large Language Models (LLMs). It provides features such as first-class streaming support, asynchronous API calls, optimized parallel execution, retries with fallbacks for reliability at scale. LCEL also allows access to intermediate results and comes equipped with inferred input/output schemas based on the chain structure which can be used for validation purposes. Furthermore, all steps are logged automatically by LangSmith for enhanced observability and debugging capabilities in complex chains. The language is compatible across different platforms including web servers like Jupyter notebooks or LangServe server while offering seamless deployment through LangServe platform itself.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "def get_documents_from_web(url):\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=200,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    splitDocs = splitter.split_documents(docs)\n",
    "    return splitDocs\n",
    "\n",
    "docs =get_documents_from_web(\"https://python.langchain.com/v0.1/docs/expression_language/\")\n",
    "\n",
    "# 初始化 OllamaLLM\n",
    "model = OllamaLLM(model='phi3') \n",
    "\n",
    "# 定義 Prompt 模板\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the user's question:\n",
    "context: {context}\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "#chain = prompt | model\n",
    "chain = create_stuff_documents_chain(\n",
    "    llm=model,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"input\" : \"What is LCEL?\",\n",
    "    \"context\" : docs\n",
    "})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
