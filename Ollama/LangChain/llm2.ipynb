{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "langchain_core.prompts.prompt.PromptTemplate() got multiple values for keyword argument 'input_variables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m b_model \u001b[38;5;241m=\u001b[39m OllamaLLM(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama3.2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 定義角色與互動方式\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m a_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m     12\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     13\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m        你是個案a，表達你在感情、健康、工作或人際關係上的憂鬱問題。\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m        請根據已知回合的對話繼續進行。\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m        對話歷史：\u001b[39m\u001b[38;5;132;01m{history}\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m        個案a的回覆：\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m b_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m     22\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     23\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 記憶對話內容\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/prompts/chat.py:1128\u001b[0m, in \u001b[0;36mChatPromptTemplate.from_template\u001b[0;34m(cls, template, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_template\u001b[39m(\u001b[38;5;28mcls\u001b[39m, template: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a template string.\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \n\u001b[1;32m   1118\u001b[0m \u001b[38;5;124;03m    Creates a chat template consisting of a single message assumed to be from\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;124;03m        A new instance of this class.\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1128\u001b[0m     prompt_template \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(template, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1129\u001b[0m     message \u001b[38;5;241m=\u001b[39m HumanMessagePromptTemplate(prompt\u001b[38;5;241m=\u001b[39mprompt_template)\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_messages([message])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/prompts/prompt.py:296\u001b[0m, in \u001b[0;36mPromptTemplate.from_template\u001b[0;34m(cls, template, template_format, partial_variables, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _partial_variables:\n\u001b[1;32m    292\u001b[0m     input_variables \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    293\u001b[0m         var \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m input_variables \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _partial_variables\n\u001b[1;32m    294\u001b[0m     ]\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    297\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39minput_variables,\n\u001b[1;32m    298\u001b[0m     template\u001b[38;5;241m=\u001b[39mtemplate,\n\u001b[1;32m    299\u001b[0m     template_format\u001b[38;5;241m=\u001b[39mtemplate_format,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     partial_variables\u001b[38;5;241m=\u001b[39m_partial_variables,\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    302\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: langchain_core.prompts.prompt.PromptTemplate() got multiple values for keyword argument 'input_variables'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
